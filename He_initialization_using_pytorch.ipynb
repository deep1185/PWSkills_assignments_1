{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+JbsCsmx5bUPOTKv0JcBz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deep1185/PWSkills_assignments_1/blob/main/He_initialization_using_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "He initialization is a technique used to initialize the weights of neural networks, particularly for layers using ReLU (Rectified Linear Unit) activation functions. It helps in maintaining the variance of the outputs of each layer to be the same as the inputs, which can help in training deep networks.\n",
        "\n",
        "Below are implementations of He initialization in both TensorFlow and PyTorch."
      ],
      "metadata": {
        "id": "Lq_yrpScX-W1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "He Initialisation using TensorFlow"
      ],
      "metadata": {
        "id": "_z7U0IugYdme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define a dense layer with He initialization\n",
        "def dense_layer_he(inputs, units):\n",
        "    # number of input features\n",
        "    input_dim = inputs.shape[-1]\n",
        "\n",
        "    # He initialization: stddev = sqrt(2.0 / input_dim)\n",
        "    initializer = tf.keras.initializers.HeNormal()\n",
        "\n",
        "    # Create a dense layer with He initialization\n",
        "    layer = tf.keras.layers.Dense(\n",
        "        units,\n",
        "        kernel_initializer=initializer,\n",
        "        activation='relu'\n",
        "    )\n",
        "\n",
        "    return layer(inputs)\n",
        "\n",
        "# Example usage\n",
        "inputs = tf.random.normal([32, 128])  # Batch of 32 samples, each with 128 features\n",
        "outputs = dense_layer_he(inputs, 64)  # Output with 64 units\n",
        "print(outputs.shape)  # Output shape: (32, 64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFpCLivnX_xR",
        "outputId": "681a7cc3-6851-432d-8589-7fa37ffaf1a9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "He Initialisation using PyTorch"
      ],
      "metadata": {
        "id": "_zUwarsFYjMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define a linear layer with He initialization\n",
        "class DenseLayerHe(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(DenseLayerHe, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "        # Apply He initialization\n",
        "        nn.init.kaiming_normal_(self.linear.weight, mode='fan_in', nonlinearity='relu')\n",
        "        nn.init.zeros_(self.linear.bias)  # Initialize bias to zeros\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.relu(self.linear(x))\n",
        "\n",
        "# Example usage\n",
        "input_dim = 128\n",
        "output_dim = 64\n",
        "inputs = torch.randn(32, input_dim)  # Batch of 32 samples, each with 128 features\n",
        "layer = DenseLayerHe(input_dim, output_dim)\n",
        "outputs = layer(inputs)\n",
        "print(outputs.shape)  # Output shape: torch.Size([32, 64])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3vTsvRgYZv5",
        "outputId": "783934e5-ccc4-45ea-85bc-1a66c124dfba"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CE7RihkbYbRc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}